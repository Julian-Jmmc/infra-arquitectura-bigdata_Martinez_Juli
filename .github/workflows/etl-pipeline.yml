name: ETL Pipeline Automation

on:
  push:
    branches:
      - main

jobs:
  ingestion:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ›ï¸ Checkout del repositorio
        uses: actions/checkout@v3

      - name: ğŸ”„ Rebase antes de ingestar
        run: |
          git pull --rebase origin main

      - name: ğŸ Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: ğŸ“¦ Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸš€ Ejecutar script de ingesta (EA1)
        run: python src/bigdata/ingestion.py

<<<<<<< HEAD:.github/workflows/etl-pipeline.yml
      - name: ğŸš€ Ejecutar script de limpieza (EA2)
=======
      # Nuevo paso para la EA2: Limpieza y preprocesamiento
      - name: ğŸš€ Ejecutar script de limpieza
>>>>>>> 722852543299d6ebbc376f9f73370e5c103a54ed:.github/workflows/main.yml
        run: python src/bigdata/cleaning.py

      - name: ğŸ“‚ Configurar Git
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: ğŸ“¤ Hacer commit de los cambios
        run: |
          git add .
<<<<<<< HEAD:.github/workflows/etl-pipeline.yml
          git commit -m "ActualizaciÃ³n AutomÃ¡tica de Datos (EA1) y (EA2) âœ…ğŸ‰" || echo "No hay cambios para commitear"
=======
          git commit -m "ActualizaciÃ³n AutomÃ¡tica de Datos y Limpieza âœ…ğŸ‰" || echo "No hay cambios para commitear"
>>>>>>> 722852543299d6ebbc376f9f73370e5c103a54ed:.github/workflows/main.yml
          git push https://${{ secrets.GITHUB_TOKEN }}@github.com/Julian-Jmmc/infra-arquitectura-bigdata_Martinez_Juli.git
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  docker-build:
    needs: ingestion
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ›ï¸ Checkout del repositorio
        uses: actions/checkout@v3

      - name: ğŸ³ Construir y ejecutar contenedor Docker
        run: |
          docker build -t bigdata-ingestion .
          docker run --rm bigdata-ingestion