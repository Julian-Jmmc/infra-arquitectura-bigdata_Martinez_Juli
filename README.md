# infra-arquitectura-bigdata_Martinez_Julian ğŸš€

<div align="center">
  <h1>Infraestructura y Arquitectura para Big Data</h1>
  <h2>Proyecto Integrador: Parte 1 EA1 - IngestiÃ³n de Datos desde un API ğŸ“Š</h2>
</div>

---

Este proyecto es un flujo de ingesta de datos del **COVID-19** desde la API pÃºblica del **COVID Tracking Project** ğŸ˜·, con almacenamiento en **SQLite** ğŸ’¾, generaciÃ³n de un archivo **Excel** de muestra ğŸ“ˆ y un reporte de auditorÃ­a ğŸ“‹. AdemÃ¡s, cuenta con un flujo de integraciÃ³n continua en **GitHub Actions** ğŸ¤– que automatiza la ejecuciÃ³n del script y la construcciÃ³n de la imagen Docker ğŸ³.

---

> **Importante:**  
> El COVID Tracking Project finalizÃ³ la recolecciÃ³n de datos el **7 de marzo de 2021** ğŸ“†, por lo que la informaciÃ³n disponible es histÃ³rica y no se actualiza mÃ¡s allÃ¡ de esa fecha.

---

## 1. DescripciÃ³n General ğŸŒŸ

Este proyecto realiza las siguientes tareas:

- ğŸ“¥ **Descarga de datos:**  
  Descarga datos histÃ³ricos de COVID-19 de los EE.UU. desde la API del COVID Tracking Project.
  - **PÃ¡gina web del API:**  
    [https://covidtracking.com/data/api](https://covidtracking.com/data/api)
  - **Formato JSON:**  
    [https://api.covidtracking.com/v1/us/daily.json](https://api.covidtracking.com/v1/us/daily.json)
  - **Formato CSV (opcional):**  
    [https://api.covidtracking.com/v1/us/daily.csv](https://api.covidtracking.com/v1/us/daily.csv)
  - **Recurso adicional:**  
    [Las mejores APIs pÃºblicas para practicar](https://ed.team/blog/las-mejores-apis-publicas-para-practicar)

- ğŸ—„ï¸ **Base de datos SQLite:**  
  Crea (o actualiza) una base de datos para almacenar la informaciÃ³n.

- ğŸ“Š **GeneraciÃ³n de archivo Excel:**  
  Genera un archivo Excel con los Ãºltimos 50 registros a modo de muestra.

- ğŸ“ **Informe de auditorÃ­a:**  
  Crea un informe de auditorÃ­a (archivo de texto) comparando la cantidad de registros en la API y en la base de datos.

- ğŸš€ **AutomatizaciÃ³n:**  
  Automatiza la ejecuciÃ³n de la ingesta y la construcciÃ³n de la imagen Docker a travÃ©s de GitHub Actions.

---

Al finalizar, tendrÃ¡s:

- ğŸ—ƒï¸ Una base de datos `ingestion.db`.
- ğŸ“‘ Un archivo Excel `ingestion.xlsx` con 50 registros en la carpeta `xlsx`.
- ğŸ“œ Un archivo de auditorÃ­a `ingestion.txt` con un resumen de los datos procesados.
- ğŸ¤– Un pipeline en GitHub Actions que ejecuta estos pasos automÃ¡ticamente.

---

## 2. Acerca de la API (COVID Tracking Project) ğŸ“¡

El COVID Tracking Project fue una iniciativa que recopilÃ³ datos de COVID-19 en EE.UU. hasta el **7 de marzo de 2021**. A partir de esa fecha, la recolecciÃ³n de datos se detuvo y la informaciÃ³n quedÃ³ congelada como un registro histÃ³rico. Algunas consideraciones importantes:

- **URL Base:**  
  [https://api.covidtracking.com](https://api.covidtracking.com)
- **Endpoint de Datos HistÃ³ricos (JSON):**  
  [https://api.covidtracking.com/v1/us/daily.json](https://api.covidtracking.com/v1/us/daily.json)
  - *TambiÃ©n disponible en CSV:*  
    [https://api.covidtracking.com/v1/us/daily.csv](https://api.covidtracking.com/v1/us/daily.csv)
- **Formato de Respuesta:**  
  JSON
- **Licencia:**  
  CC BY 4.0 https://covidtracking.com/about-data/license

**Campos Principales:**
- `date`: Fecha del reporte
- `positive`: Casos positivos acumulados
- `death`: Fallecimientos confirmados o probables
- `hospitalizedCurrently`: Hospitalizados
- `totalTestResults`: NÃºmero total de tests reportados
- `positiveIncrease`: Nuevos casos
- `deathIncrease`: Nuevas muertes
- `lastModified`: Ãšltima fecha/hora de actualizaciÃ³n

---

## 3. Requerimientos Previos âœ…

Antes de ejecutar el proyecto, asegÃºrate de contar con los siguientes requisitos:

- ğŸ **Python 3.9 o superior (Recomendado: 3.13.2)** instalado en tu sistema.
- ğŸŒ **Git** instalado (para clonar el repositorio, aunque puedes descargar el ZIP directamente).
- ğŸ³ **(Opcional) Docker**, si deseas ejecutar el proyecto en un contenedor o utilizar el pipeline de Docker en GitHub Actions.
- ğŸ”— **ConexiÃ³n a Internet** para descargar los datos.
- ğŸ¤– **Una cuenta en GitHub**, si quieres aprovechar la automatizaciÃ³n con GitHub Actions.

---

## 4. Clonar o Descargar el Proyecto ğŸ“‚

### ğŸ”¹ Clonar con Git  
Ejecuta el siguiente comando en tu terminal:  

```bash
git clone https://github.com/Alexis-Machado/infra-arquitectura-bigdata_Alexis_Machado.git
```

---

> **Nota:**  
> Las carpetas `auditoria/`, `db/` y `xlsx/` se crean vacÃ­as en el repositorio, pero el cÃ³digo las poblarÃ¡ en tiempo de ejecuciÃ³n.  
> No te preocupes si las ves vacÃ­as inicialmente. ğŸ—‚ï¸

---

## 5. CreaciÃ³n y ActivaciÃ³n de un Entorno Virtual (Recomendado) ğŸ› ï¸

Para mantener organizadas las dependencias del proyecto y evitar conflictos con otras instalaciones de Python, se recomienda usar un entorno virtual.


### ğŸ”¹ Crear el entorno virtual  
Ejecuta el siguiente comando dentro de la carpeta del proyecto:  

```bash
python -m venv venv
```

ğŸ”¹ Activar el entorno virtual

ğŸ”¹ En Windows ğŸ–¥ï¸

```bash
venv\Scripts\activate
```

ğŸ”¹ En Linux/Mac ğŸ’»

```bash
source venv/bin/activate
```

ğŸ”¹ Verificar la activaciÃ³n âœ…
Si el entorno se activÃ³ correctamente, deberÃ­as ver (venv) al inicio de tu lÃ­nea de comandos.

---

## 6. InstalaciÃ³n de Dependencias y Uso de `setup.py` ğŸ“¦

Para ejecutar el proyecto correctamente y facilitar su instalaciÃ³n, es necesario instalar las bibliotecas requeridas y utilizar `setup.py`.

### ğŸ”¹ InstalaciÃ³n de dependencias  

Ejecuta los siguientes comandos en la raÃ­z del proyecto (asegÃºrate de tener el entorno virtual activo si lo estÃ¡s usando):  

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

Esto instalarÃ¡ todas las bibliotecas necesarias para el proyecto (por ejemplo: requests, pandas, openpyxl, etc.). âœ…

## ğŸ”¹ Recomendado Uso de setup.py (Empaquetado e InstalaciÃ³n)
El proyecto incluye un setup.py que permite instalarlo como un paquete Python local.

AsegÃºrate de estar en el directorio raÃ­z del proyecto (donde estÃ¡ setup.py).
Para instalarlo, ejecuta:

```bash
pip install -e .
```

Esto instalarÃ¡ el paquete en tu entorno Python y permitirÃ¡ modificar el cÃ³digo sin necesidad de reinstalarlo.

---

## 7. EjecuciÃ³n del Proyecto (Local) ğŸš€  

Para ejecutar el proyecto, asegÃºrate de tener el entorno virtual activo (si lo estÃ¡s utilizando) o haber instalado las dependencias globalmente. Luego, ejecuta el script principal:  

```bash
python src/bigdata/ingestion.py
```

ğŸ”¹ Ejemplo de salida en consola
Al ejecutar el script, verÃ¡s un proceso similar a este:

```bash
Comenzando la Ingesta de Datos de COVID-19...
Â¡Datos obtenidos! Se han obtenido 420 Registros HistÃ³ricos del COVID-19 en EE.UU
Los Datos del COVID-19 se han Almacenado en la Base de Datos SQLite
Archivo de Excel Generado en: ...\src\bigdata\static\xlsx\ingestion.xlsx
AuditorÃ­a Generada en: ...\src\bigdata\static\auditoria\ingestion.txt
Â¡Proceso Finalizado con Ã‰xito!
```

ğŸ”¹ Archivos generados al finalizar

âœ” Base de datos SQLite:
ğŸ“‚ Se crearÃ¡ (o actualizarÃ¡) el archivo ingestion.db en src/bigdata/static/db/.

âœ” Archivo Excel de muestra:
ğŸ“Š Se generarÃ¡ un archivo ingestion.xlsx con 50 registros en src/bigdata/static/xlsx/.

âœ” Informe de auditorÃ­a:
ğŸ“ Un archivo ingestion.txt estarÃ¡ disponible en src/bigdata/static/auditoria/.

Â¡Listo! El proceso de ingesta y almacenamiento de datos ha sido completado con Ã©xito. ğŸ‰

---
 
## 8. EjecuciÃ³n del Proyecto con Docker ğŸ³ (Opcional)

Si prefieres ejecutar todo dentro de un contenedor Docker, sigue estos pasos:

Crear la imagen Docker (en la raÃ­z del proyecto, donde estÃ¡ el Dockerfile):

```bash
docker build -t bigdata-ingestion .
```

Ejecutar el contenedor:

```bash
docker run --name bigdata_container bigdata-ingestion
```

Este comando crearÃ¡ un contenedor llamado `bigdata_container` que ejecutarÃ¡ el script `ingestion.py`.

Para ver los archivos generados (base de datos, Excel, auditorÃ­a) dentro del contenedor, puedes montar un volumen o copiar los archivos al host. Un ejemplo simple de montar el directorio actual al contenedor:

```bash
docker run -v ${PWD}/src/bigdata/static:/app/src/bigdata/static bigdata-ingestion
```

De esta manera, verÃ¡s los archivos en tu mÃ¡quina local en la carpeta `src/bigdata/static/`.

Si el contenedor ya se ejecutÃ³ y deseas copiar los archivos generados manualmente a tu sistema local, usa:

```bash
docker cp bigdata_container:/app/src/bigdata/static ./src/bigdata/static
```

DespuÃ©s de la ejecuciÃ³n, deberÃ­as ver los siguientes archivos en `src/bigdata/static/`:

- ğŸ—ƒï¸ `db/ingestion.db` â†’ Base de datos SQLite con los datos procesados.
- ğŸ“‘ `xlsx/ingestion.xlsx` â†’ Archivo Excel con los Ãºltimos 50 registros.
- ğŸ“ `auditoria/ingestion.txt` â†’ Informe de auditorÃ­a con el resumen de datos.

Â¡Listo! Ahora tienes tu proyecto ejecutÃ¡ndose en Docker con todos los archivos generados correctamente. ğŸš€

---

## 9. AutomatizaciÃ³n con GitHub Actions ğŸ¤–

Este proyecto incluye un flujo de trabajo en `.github/workflows/main.yml` que automatiza:

- ğŸ“¥ **Ingesta de datos**: Ejecuta el script `ingestion.py`.
- ğŸ“¤ **Commit automÃ¡tico**: Guarda los cambios en la base de datos, Excel y auditorÃ­a si hay modificaciones.
- ğŸ³ **ConstrucciÃ³n y ejecuciÃ³n de Docker**: Crea y ejecuta la imagen del contenedor.

### ğŸ”¹ 9.1 Estructura del Flujo de Trabajo  

El archivo de configuraciÃ³n `.github/workflows/main.yml` tiene el siguiente contenido:

```yaml
name: Data Ingestion Automation

on:
  push:
    branches:
      - main

jobs:
  ingestion:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ›ï¸ Checkout del repositorio
        uses: actions/checkout@v3

      - name: ğŸ”„ Rebase antes de ingestar
        run: |
          git pull --rebase origin main

      - name: ğŸ Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: ğŸ“¦ Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ğŸš€ Ejecutar script de ingesta
        run: python src/bigdata/ingestion.py

      - name: ğŸ“‚ Configurar Git
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: ğŸ“¤ Hacer commit de los cambios
        run: |
          git add .
          git commit -m "ActualizaciÃ³n AutomÃ¡tica de Datos âœ…ğŸ‰" || echo "No hay cambios para commitear"
          git push https://${{ secrets.GITHUB_TOKEN }}@github.com/Alexis-Machado/infra-arquitectura-bigdata_Alexis_Machado.git
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  docker-build:
    needs: ingestion
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ›ï¸ Checkout del repositorio
        uses: actions/checkout@v3

      - name: ğŸ³ Construir y ejecutar contenedor Docker
        run: |
          docker build -t bigdata-ingestion .
          docker run --rm bigdata-ingestion

```

ğŸ”¹ 9.2 ExplicaciÃ³n del Flujo
ğŸ¯ Evento de disparo:

Cada vez que se hace un push a la rama main, se ejecutan los siguientes jobs:

âœ… ingestion
Descarga el repositorio (checkout).

Configura Python 3.9.

Instala las dependencias (requirements.txt).

Ejecuta el script de ingesta ingestion.py.

Configura Git para realizar commits automÃ¡ticos desde GitHub Actions.

Realiza un commit de los cambios generados (nuevos datos, Excel, auditorÃ­a) si existen.

ğŸ³ docker-build (depende de ingestion)

Descarga el repositorio (checkout).

Construye la imagen Docker (docker build).

Ejecuta el contenedor Docker (docker run).


ğŸ”¹ 9.3 CÃ³mo Personalizarlo ğŸ”§

Cambiar la rama en la que se dispara el flujo:

Si deseas que la automatizaciÃ³n se ejecute en otra rama, edita:

```yaml
on:
  push:
    branches:
      - main
```

ğŸ“Œ Ajustar la versiÃ³n de Python:

Si necesitas otra versiÃ³n de Python, cambia:

```yaml
with:
  python-version: '3.9'
```

ğŸ”— Configurar la URL del repositorio:
AsegÃºrate de que el paso git push apunte a tu repositorio:

```yaml
git push https://${{ secrets.GITHUB_TOKEN }}@github.com/TU_USUARIO/TU_REPO.git main
```

ğŸ“Š Ver logs y resultados:

Para revisar la ejecuciÃ³n, dirÃ­gete a la pestaÃ±a Actions en tu repositorio de GitHub.

ğŸš€ Â¡Listo! Con este flujo de trabajo, la ingesta de datos y la construcciÃ³n de Docker se ejecutarÃ¡n automÃ¡ticamente cada vez que subas cambios al repositorio. ğŸ‰

---

## 10. ConclusiÃ³n ğŸ¯  

Con este proyecto, has construido un **pipeline de extracciÃ³n, transformaciÃ³n y carga (ETL)** para datos de COVID-19.  

ğŸ”¹ **Flujo del Proyecto:**  
âœ… **ExtracciÃ³n**: ObtenciÃ³n de datos desde la API del **COVID Tracking Project**.  
âœ… **TransformaciÃ³n**: Limpieza y almacenamiento en una base de datos **SQLite**.  
âœ… **Carga**: GeneraciÃ³n de un reporte en **Excel** y un archivo de **auditorÃ­a**.  
âœ… **AutomatizaciÃ³n**: IntegraciÃ³n con **GitHub Actions** para ejecutar el flujo y construir un contenedor **Docker** automÃ¡ticamente.  


ğŸ‰ Â¡Felicidades! Has finalizado el desarrollo de este proyecto con Ã©xito. ğŸš€

--- 

## Autores

<div align="center">
  <img src="https://www.iudigital.edu.co/images/11.-IU-DIGITAL.png" alt="IU Digital" width="350">

  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  <h1>ğŸ“‹ Evidencia de Aprendizaje 1<br>
  <sub>IngestiÃ³n de Datos desde un API</sub></h1>
  <h3>Parte 1 del Proyecto Integrador</h3>

  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  ### ğŸ‘¥ **Integrantes**
  **Jhon Alexis Machado RodrÃ­guez**  
  **JuliÃ¡n JosÃ© MartÃ­nez Camacho**

  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  #### ğŸ“ **IngenierÃ­a de Software y Datos**  
  #### ğŸ›ï¸ InstituciÃ³n Universitaria Digital de Antioquia  
  #### ğŸ“… Semestre 9Â°  
  #### ğŸ“¦ Infraestructura y arquitectura para Big Data
  #### ğŸ”– PREICA2501B010112
  #### ğŸ‘¨â€ğŸ«ğŸ« andres felipe callejas  

  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  **ğŸ—“ï¸ 2 de marzo del 2025**  
</div>
